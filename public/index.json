[
{
	"uri": "http://localhost/",
	"title": "AWS Modernization DevSecOps Workshop",
	"tags": [],
	"description": "",
	"content": " AWS Modernization DevSecOps Workshop Welcome In this workshop, you will learn how to add security testing to a CI/CD pipeline of a dockerized .net (Unicorn Store) application using AWS CodeCommit, AWS CodeBuild, and AWS CodePipeline. The modules contained in this workshop will provide you with step-by-step instructions for committing, building, testing, and deploying software in an automation fashion. You will also learn about some basic security tests and where to instrument them in the software development lifecycle. Objectives  Gain familiarity with the workflow of a modern application Learn where to add security testing to a CI/CD pipeline Learn about AWS services used to orchestrate testing  What we will cover in this workshop  Setup of a Cloud9 environment Usage of AWS CloudFormation to automate the deployment of infrastructure Deployment of Amazon Elastic Container Service Deploy and use a modenized pipeline using AWS CodePipeline, CodeCommit, and CodeBuild Instrument a couple of security testing/scanning tools  Sample reference architecture At the conclusion of this workshop, you will end up with various AWS services provisioned in your AWS account. The following diagram illustrates some of these services and is intended as a sample reference architecture. Workshop flow Each section or module contained in this workshop is designed to guide you through each step of the process to build the architecture referenced above. This is accomplished by using AWS Cloud 9 as our starting point along with a `git clone` of the content from our repository. Everything you need is provided to you including sample code, AWS CloudFormation templates, and detailed instructions. We will be using the AWS CLI from our Cloud9 instance to deploy the CloudFormation templates and build out our environment. The examples and sample code provided in this workshop are intended to be consumed as instructional content. These will help you understand how various AWS services can be architected to build a solution while demonstrating best practices along the way. These examples are not intended for use in production environments.  "
},
{
	"uri": "http://localhost/50_conclusion/1_after_thoughts.html",
	"title": "Congratulations",
	"tags": [],
	"description": "",
	"content": " Well Done Congratulations. You have completed this DevSecOps workshop on shifting security testing left.\nRecap on what you have learned  Learned how to deploy CloudFormation stacks Learned about a modern CI/CD pipeline Learned how to test in AWS CodeBuild Learned about a couple of open source tools for security testing Learned why it is important to test as early as possible in the pipeline  Final Thoughts Due to the time and scope of the workshop there are several things that can and should be instrumented to improve security testing within the CI/CD pipeline. Here are a few suggestions to go above and beyond what you have learned in this workshop.\n Add notifications that provide feedback to developers using technology that developers are already familiar with and using. For build failures send to a slack channel, SMS, or email notifications using Amazon Simple Notification Service (SNS) and AWS Lambda. Use a branching method such as gitflow and test branches awaiting a pull request review. Utilize blue/green deployments to instrument additional security testing prior to production deployment. Enable git hooks to automate testing right when a developer commits code on her/his local machine. Add additional testing such as language specific linters, SAST, DAST, dependency CVE scanning, IAST, and RASP. Implementation should be similiar to what we accomplished in this workshop.  The sky\u0026rsquo;s the limit on adding additional features and functionality to DevSecOps. The point is to monitor your pipeline and continually make improvements to accelerate the release of features and functionality to your end customers.\nNext Steps Try and implement some of the learnings from the workshop on your company\u0026rsquo;s development process. Don\u0026rsquo;t try and do too much at one time and use an agile iterative approach. Remember that you are also trying to change culture by baking in security so don\u0026rsquo;t try and do too much too fast.\n"
},
{
	"uri": "http://localhost/10_prerequisites/1_aws_account.html",
	"title": "Create an AWS account",
	"tags": [],
	"description": "",
	"content": "Your account must have the ability to create new IAM roles and scope other IAM permissions.  If you already have an AWS account, and have IAM Administrator access, you can skip this page.   If you don\u0026rsquo;t already have an AWS account with Administrator access: create one now\n Once you have an AWS account, ensure you are following the remaining workshop steps as an IAM user with administrator access to the AWS account: Create a new IAM user to use for the workshop\n Enter the user details:  Attach the AdministratorAccess IAM Policy:  Click to create the new user:  Take note of the login URL and save:   "
},
{
	"uri": "http://localhost/20_getting-started/1_getting_started.html",
	"title": "Creating your environment",
	"tags": [],
	"description": "",
	"content": " You are responsible for the cost of the AWS services used while running this workshop in your AWS account.  In order for you to succeed in this workshop, you will need to run through a few steps in order to properly setup and configure your environment. These steps will include provisioning some services, installing some tools, and downloading some dependencies as well. We will begin with AWS Cloud9. Technically, you should be able to complete many of the steps in these modules if you have a properly configured terminal. However, in order to avoid the \u0026ldquo;works on my machine\u0026rdquo; response you\u0026rsquo;ve surely experienced at some point in your career, I strongly encourage you to proceed with launching Cloud9.\n[AWS Cloud9](https://aws.amazon.com/cloud9/) is a cloud-based integrated development environment (IDE) that lets you write, run, and debug your code with just a browser. It includes a code editor, debugger, and terminal. Cloud9 comes prepackaged with essential tools for popular programming languages, including JavaScript, Python, PHP, and more, so you donâ€™t need to install files or configure your development machine to start new projects.  Deploy \u0026amp; Launch AWS Cloud9 Click here to deploy using CloudFormation template\n Create stack click, Next Specify stack details, click Next Configure stack options, click Next Review UnicornDevSecOpsWorkshop, scroll to bottom section under Capabilities and check both boxes and click Create stack   The deployment process takes approximately 2-3 minutes to complete. In the meantime, you can review the deployment guide while you wait.\n Once the installation is complete, go to Cloud9 within the console and click on Open IDE on the name that begins with WorkshopIDE.\nClone the source repository for this workshop Now we want to clone the repository that contains all the content and files you need to complete this workshop.\ncd ~/environment \u0026amp;\u0026amp; \\ git clone https://github.com/jamesbland123/modernization-devsecops-workshop.git Increase AWS Cloud9 disk/storage cd ~/environment/modernization-devsecops-workshop/scripts ./resize.sh 50 Update and install some tools This step updates and installs various tools needed to complete the workshop. Feel free to look at the script if you are curious about what gets updated and installed.\n./getting_started.sh Next, lets source .bashrc to add .net PATH to our current working environment\n. ~/.bashrc The last few lines of the output will look similar to the below window   Deleted: sha256:84e9cc454dd9325a12774267998ebb5adca00dd5907c73b447fd3437611209d0 Deleted: sha256:c8462350bd81d6d8264a9e682949efe0c650f1a3a6800ceccf335e70bbcdf1f9 Deleted: sha256:0c5fd0b1e438aa8d08d6ca8e0bcf1121e897987d1b24495467cb18b1d9104e19 Deleted: sha256:88e3926a38f1a1d6e57eadbfc2cbcc27f46d954b58e9dfc902e05879cd8f99b9 xxxyyy_user:~/environment/modernization-devsecops-workshop/scripts (master) $ . ~/.bashrc function xxxyyy_user:~/environment/modernization-devsecops-workshop/scripts (master) $  "
},
{
	"uri": "http://localhost/30_unicorn_store_ci_cd/1_base_services.html",
	"title": "Setup Basic Services",
	"tags": [],
	"description": "",
	"content": " Introduction Up until now, we have been going through various steps to setup our environment. Installing tools and other necessary steps to make sure we progress through the modules without any issues. Now, we are ready to begin deploying the infrastructure that will support our Unicorn Store application.\nBasic Services CloudFormation Stack We are going to setup some basic services such as an Amazon RDS Database, secrets in AWS Secrets Manager, AWS CodeCommit, and Amazon ECR services.\nThis step takes approximately 15 minutes  Copy and paste the following into Cloud9\u0026rsquo;s terminal to launch a CloudFormation stack\ncd ~/environment/modernization-devsecops-workshop/cfn aws cloudformation create-stack --stack-name UnicornStoreServices --template-body file://unicorn-store-services.yaml --capabilities CAPABILITY_NAMED_IAM until [[ `aws cloudformation describe-stacks --stack-name \u0026#34;UnicornStoreServices\u0026#34; --query \u0026#34;Stacks[0].[StackStatus]\u0026#34; --output text` == \u0026#34;CREATE_COMPLETE\u0026#34; ]]; do echo \u0026#34;The stack is NOT in a state of CREATE_COMPLETE at `date`\u0026#34;; sleep 30; done \u0026amp;\u0026amp; echo \u0026#34;The Stack is built at `date` - Please proceed\u0026#34; The output should look like the window below  The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:09:55 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:10:26 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:10:56 UTC 2019 The Stack is built at Sun Aug 4 05:11:27 UTC 2019 - Please proceed xxxyyy_user:~/environment/modernization-devsecops-workshop/cfn (master) $ \n"
},
{
	"uri": "http://localhost/40_security_testing/1_introduction.html",
	"title": "Testing Introduction",
	"tags": [],
	"description": "",
	"content": "In this module, we\u0026rsquo;re going to instrument security testing within the CI/CD process. Modernized applications look to shift security left. By enabling security testing sooner in the development process developers can receive feedback while the software change is still top of mind.\nIn traditional software development processes security testing is not performed until one of the final checks before release to production. With this scenario, feedback to the developer is often delayed weeks or even months from the time code was commited. This type of delay causes toil with developers as now there are 100\u0026rsquo;s if not 1000\u0026rsquo;s of changes that need to be reviewed.\nBy instrumenting tests early in the development cycle developers receive timely feedback. When done in the pipeline the process can trigger the build to fail and alert developers to an issue with the latest commit and prevent risky software changes from being rolled out to production.\n"
},
{
	"uri": "http://localhost/40_security_testing/5_test_pipeline.html",
	"title": "Test Pipeline",
	"tags": [],
	"description": "",
	"content": " AWS CodePipeline Workflow A pipeline models our workflow from end to end. Within our pipeline we can have stages, and you can think of stages as groups of actions. An action or a plug-in is what acts upon the current revision that is moving through your pipeline. This is where the actual work happens in your pipeline. Stages can then be connected by transitions and in our console we represent these by an arrow between each stage. Our pipeline will consist of three stages:\nThe Source stage monitors for changes to our source code repository. When a change is made, we will transition to the following stage. In this case, our Build stage. Here we will use CodeBuild to run various tests within our pipeline. The process will check for various security issues and fail the build if any are found. These various phases are defined within our BuildSpec which will be found in the buildspec.yml in the source code directory. A sample of this file is below:\n version: 0.2 phases: install: runtime-versions: docker: 18 pre_build: commands: - $(aws ecr get-login --region $AWS_DEFAULT_REGION --no-include-email) - COMMIT_HASH=$(echo $CODEBUILD_RESOLVED_SOURCE_VERSION | cut -c 1-7) - IMAGE_TAG=${COMMIT_HASH:=latest} - echo Setting CodeCommit Credentials - git config --global credential.helper '!aws codecommit credential-helper $@' - git config --global credential.UseHttpPath true - echo Installing TruffleHog - pip install TruffleHog build: commands: - echo Running TruffleHog Secrets Scan - trufflehog --regex --max_depth 1 $APP_SOURCE_REPO_URL - echo Scanning with Hadolint - docker run --rm -i hadolint/hadolint imagedefinitions.json artifacts: files: imagedefinitions.json  Our particular tests will be part of the build stage in the buildspec.yml file. The tests will run prior to building the Docker image. This particular point within the build stage is chosen as it allows feedback at the earliest point within the CI/CD pipeline for the type of test that is instrumented. Once the security testing is complete and successful, our build stage starts our Docker image build. When the new Docker image has been successfully built and stored in ECR, we transition to our final stage where we deploy the image to our AWS Fargate cluster. During the Deploy stage, we will then consume the imagedefinitions.json output from the post_build process to sping up a new container using our newly created image into our existing cluster.\nIt is not covered in this workshop, but additional testing such as penetration test and other black box testing methods can be instrumented in the *post_build* phase within the *buildspec.yml*. The *post_build* phase is where you would place any testing and instructions that are completed after a Docker image has been built.  "
},
{
	"uri": "http://localhost/50_conclusion/10_cleanup.html",
	"title": "Cleanup",
	"tags": [],
	"description": "",
	"content": " Cleanup In order to prevent charges to your account we recommend cleaning up the infrastructure that was created. If you plan to keep things running so you can examine the workshop a bit more please remember to do the cleanup when you are done. It is very easy to leave things running in an AWS account, forget about it, and then accrue charges.\nYou will need to manually delete some resources before you delete the CloudFormation stacks so please do the following steps in order. With the CloudFormation Stacks, delete one at a time and validate the stack is removed before deleting the next stack.  # Delete S3 Bucket aws s3 rm s3://$(aws s3api list-buckets --query \u0026#39;Buckets[?starts_with(Name, `unicornpipeline-artifactbucket`) == `true` ].Name\u0026#39; --output text) --recursive # Delete Log Group aws logs delete-log-group --log-group-name UnicornStore # Delete ECR Repository aws ecr delete-repository --repository-name modernization-devsecops-workshop --force # Delete CloudFormation Stacks aws cloudformation delete-stack --stack-name UnicornPipeline aws cloudformation delete-stack --stack-name UnicornECS aws cloudformation delete-stack --stack-name UnicornStoreServices aws cloudformation delete-stack --stack-name UnicornDevSecOpsWorkshop echo \u0026#39;Completed cleanup.\u0026#39;"
},
{
	"uri": "http://localhost/10_prerequisites.html",
	"title": "Prerequisites",
	"tags": [],
	"description": "",
	"content": " Prerequisites  Create an AWS account   "
},
{
	"uri": "http://localhost/30_unicorn_store_ci_cd/10_push_to_repo.html",
	"title": "Push to Repo",
	"tags": [],
	"description": "",
	"content": " Push to AWS CodeCommit We should now be ready to push our application to the AWS CodeCommit repo and the Amazon Elastic Container Repository\nThe following sets a new origin for the application repo to CodeCommit unicorn-store, configures a credential helper needed for CodeCommit, and pushes the source code to the repo. This step is necessary for an automated pipeline as CodeBuild will build the Unicorn Store application directly from this repo.\ncd ~/environment/modernization-devsecops-workshop/ git remote set-url origin https://git-codecommit.us-west-2.amazonaws.com/v1/repos/unicorn-store git config --global credential.helper \u0026#39;!aws codecommit credential-helper $@\u0026#39; git config --global credential.UseHttpPath true git push origin master If successfully, you should see the message as below.   Counting objects: 9525, done. Compressing objects: 100% (5900/5900), done. Writing objects: 100% (9525/9525), 33.75 MiB | 2.65 MiB/s, done. Total 9525 (delta 3240), reused 9525 (delta 3240) remote: processing To https://git-codecommit.us-west-2.amazonaws.com/v1/repos/unicorn-store * [new branch] master - master  Push to Amazon Elastic Container Repository (ECR) Now it\u0026rsquo;s time to compile and package your code. Copy and paste the below code into Cloud9\u0026rsquo;s terminal window\ncd ~/environment/modernization-devsecops-workshop/ docker-compose build docker tag modernization-devsecops-workshop_unicornstore:latest $(aws ecr describe-repositories --repository-name modernization-devsecops-workshop --query=repositories[0].repositoryUri --output=text):latest eval $(aws ecr get-login --no-include-email) docker push $(aws ecr describe-repositories --repository-name modernization-devsecops-workshop --query=repositories[0].repositoryUri --output=text):latest If you watch the screen you should see the docker image build process animating the terminal\nIf successfully, you should see the message as below.   The push refers to repository [1234567891011.dkr.ecr.us-west-2.amazonaws.com/modernization-unicorn-store] 8d2f7b95f78d: Pushed 82852e5eaa9d: Pushed 9df07df94e41: Pushed aa90bcce39de: Pushed d9ff549177a9: Pushed latest: digest: sha256:4229b5fe142f6d321ef2ce16ff22070e410272ee140e7eec51540a823dcd315a size: 1369  "
},
{
	"uri": "http://localhost/40_security_testing/10_secrets_scanning.html",
	"title": "Secrets Scanning",
	"tags": [],
	"description": "",
	"content": "In this stage you are going to test for secrets accidentally saved in your repository. For this stage you\u0026rsquo;ll be leveraging trufflehog, a popular open source project for finding secrets accidentally committed in repositories. It essentially searches through git repositories for secrets, digging deep into commit history and branches. It identifies secrets by running entropy checks as well as high signal regex checks.\nTo get started, lets open up buildspec.yml in the left hand pane of Cloud9.\nWe want to change the line that has  - trufflehog \u0026ndash;regex \u0026ndash;max_depth 1 $APP_SOURCE_REPO_URL \nto this\n- trufflehog --regex --max_depth 1000 $APP_SOURCE_REPO_URL  Notice we changed 1 to 1000\n Now save the file and run the following to push changes to our CodeCommit repository and go to CodePipeline in the console to watch our CI/CD process.\ncd ~/environment/modernization-devsecops-workshop/ git add . git commit -m \u0026#34;Updating trufflehog max_depth value\u0026#34; git push origin master Once CodePipeline detects a change to your repo it will start a new process. This time the build will fail. The Unicorn Store test repo has secrets in it\u0026rsquo;s commit history, so the build will exit out with a status of 1, causing the build to fail. While still on the Pipeline screen if you click on the Details button under Failed message it will take you to the build logs where you can review the failure. Click on it now and click Link to execution details\nNear the bottom of the log the output will look similiar to this Let\u0026rsquo;s change the buildspec.yml again so that our build passes. You typically want to set this value to a low number during your CI/CD process so only the latest commits are scanned. If you are running trufflehog offline on your local machine you may want to scan the entire commit history as you don\u0026rsquo;t want to leak secrets into your repo. We will set this back to a value of 1 so only the current commit is scanned for secrets.\nWe want to change the line that has  - trufflehog \u0026ndash;regex \u0026ndash;max_depth 1000 $APP_SOURCE_REPO_URL \nback to this\n- trufflehog --regex --max_depth 1 $APP_SOURCE_REPO_URL Now save the file and run the following to push changes to our CodeCommit repository and go to CodePipeline in the console to watch our CI/CD process.\ncd ~/environment/modernization-devsecops-workshop/ git add . git commit -m \u0026#34;Updating trufflehog max_depth value\u0026#34; git push origin master If you watch CodePipeline now the CI/CD process should now succeed.\nFor more information about truffleHog https://github.com/dxa4481/truffleHog\n"
},
{
	"uri": "http://localhost/30_unicorn_store_ci_cd/20_ecs_fargate.html",
	"title": "Deploy ECS Fargate Service",
	"tags": [],
	"description": "",
	"content": " Deploy Fargate Service In the following set of commands we are going to use CloudFormation to deploy services that will allow our Unicorn Store application to service traffic from the Internet. The CloudFormation template sets up an ECS Cluster, a Service, Task Definition, Task, and Application Load Balancer.\ncd ~/environment/modernization-devsecops-workshop/cfn aws cloudformation create-stack --stack-name UnicornECS --template-body file://unicorn-store-ecs.yaml --capabilities CAPABILITY_NAMED_IAM until [[ `aws cloudformation describe-stacks --stack-name \u0026#34;UnicornECS\u0026#34; --query \u0026#34;Stacks[0].[StackStatus]\u0026#34; --output text` == \u0026#34;CREATE_COMPLETE\u0026#34; ]]; do echo \u0026#34;The stack is NOT in a state of CREATE_COMPLETE at `date`\u0026#34;; sleep 30; done \u0026amp;\u0026amp; echo \u0026#34;The Stack is built at `date` - Please proceed\u0026#34; This step takes approximately 3 minutes and if successfully, you should see the message as below.   The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:34:25 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:34:55 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:35:26 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:35:57 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:36:27 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:36:58 UTC 2019 The Stack is built at Sun Aug 4 05:37:28 UTC 2019 - Please proceed  To test, run the following query and copy the URL you obtain from the output into the address bar of a web browser. You should see something similar to the image below.\naws elbv2 describe-load-balancers --names=\u0026#34;UnicornStore-LB\u0026#34; --query=\u0026#34;LoadBalancers[0].DNSName\u0026#34; --output=text "
},
{
	"uri": "http://localhost/40_security_testing/20_docker_scanning.html",
	"title": "Docker Scanning",
	"tags": [],
	"description": "",
	"content": "This stage you\u0026rsquo;ll add linting of Dockerfiles to help you build best practice Docker images. For linting you\u0026rsquo;ll be leveraging Hadolint, which is a popular open source project for linting Dockerfiles and validating inline bash. The linter parses the Dockerfile into an AST and performs rules on top of the AST. The rules aren\u0026rsquo;t all security specific but they have good coverage across best practices.\nTo cause a build failure we are going to edit the Dockerfile and add a line that violates a hadolint check. In the left hand pane of Cloud9, open up Dockerfile for editing.\nWe want to add the following to the end of the file RUN cd /tmp \u0026amp;\u0026amp; echo \u0026quot;hello!\u0026quot; so your Dockerfile will look like this\nFROM microsoft/dotnet:2.2-aspnetcore-runtime-alpine AS base WORKDIR /app EXPOSE 80 FROM microsoft/dotnet:2.2-sdk AS build WORKDIR /src COPY UnicornStore/UnicornStore.csproj UnicornStore/ RUN dotnet restore UnicornStore/UnicornStore.csproj COPY . . WORKDIR /src/UnicornStore RUN dotnet build UnicornStore.csproj -c Release -o /app FROM build AS publish RUN dotnet publish UnicornStore.csproj -c Release -o /app FROM base AS final WORKDIR /app COPY --from=publish /app . ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;UnicornStore.dll\u0026#34;] HEALTHCHECK --interval=30s --timeout=5s --retries=5 --start-period=30s CMD wget --quiet --tries=1 --spider http://localhost/health || exit 1 RUN cd /tmp \u0026amp;\u0026amp; echo \u0026#34;hello!\u0026#34; Go ahead and save the file then run the following commands to push a new commit to the repo and kick off a pipeline build process\ncd ~/environment/modernization-devsecops-workshop/ git add . git commit -m \u0026#34;Updating Dockerfile\u0026#34; git push origin master This time your build will fail with an exit status of 1. Hadolint rules DL3003 and SC1035 are violated with the line RUN cd /tmp \u0026amp;\u0026amp; echo \u0026quot;hello!\u0026quot;. While still on the CodePipeline screen if you click on the Details button under Failed message it will take you to the build logs where you can review the failure. Click on it now and click Link to execution details\nNear the bottom of the log the output will look similiar to this\nTo fix this we need to open up the Dockerfile and remove the offending line. Open up Dockerfile in Cloud9 and remove the line RUN cd /tmp \u0026amp;\u0026amp; echo \u0026quot;hello!\u0026quot; and save the file. The Dockerfile once edited should look like this.\nFROM microsoft/dotnet:2.2-aspnetcore-runtime-alpine AS base WORKDIR /app EXPOSE 80 FROM microsoft/dotnet:2.2-sdk AS build WORKDIR /src COPY UnicornStore/UnicornStore.csproj UnicornStore/ RUN dotnet restore UnicornStore/UnicornStore.csproj COPY . . WORKDIR /src/UnicornStore RUN dotnet build UnicornStore.csproj -c Release -o /app FROM build AS publish RUN dotnet publish UnicornStore.csproj -c Release -o /app FROM base AS final WORKDIR /app COPY --from=publish /app . ENTRYPOINT [\u0026#34;dotnet\u0026#34;, \u0026#34;UnicornStore.dll\u0026#34;] HEALTHCHECK --interval=30s --timeout=5s --retries=5 --start-period=30s CMD wget --quiet --tries=1 --spider http://localhost/health || exit 1 Go ahead and add, commit, and push the changes to your repo\ncd ~/environment/modernization-devsecops-workshop/ git add . git commit -m \u0026#34;Updating Dockerfile\u0026#34; git push origin master If you head over to CodePipeline in the console and wait for the build you will notice this time the build process succeeds. If you want to test if your Unicorn store is still functional, run the follow command in Cloud9\u0026rsquo;s terminal and copy the URL to a browser.\naws elbv2 describe-load-balancers --names=\u0026#34;UnicornStore-LB\u0026#34; --query=\u0026#34;LoadBalancers[0].DNSName\u0026#34; --output=text For more information about Hadolint https://github.com/hadolint/hadolint\n"
},
{
	"uri": "http://localhost/20_getting-started.html",
	"title": "Getting Started",
	"tags": [],
	"description": "",
	"content": " Getting Started  Creating your environment   "
},
{
	"uri": "http://localhost/30_unicorn_store_ci_cd/30_pipeline.html",
	"title": "Deploy CI/CD Pipeline",
	"tags": [],
	"description": "",
	"content": " What is CI/CD? Continuous integration (CI) and continuous delivery (CD) embodies a culture, set of operating principles, and collection of practices that enable application development teams to deliver features and functionality more frequently and reliably.\nContinuous integration is a coding philosophy and set of practices that drive development teams to implement small changes and check in code to version control repositories as frequently as possible. Because most modern applications require developing code in different platforms and tools, the team needs a mechanism to integrate and validate its changes.\nA goal of CI is to establish a consistent and automated way to build and test applications. With consistency in the integration process in place, teams are more likely to commit code changes more frequently, which leads to better collaboration and software quality through feedback loops.\nContinuous delivery picks up where continuous integration ends. CD automates the delivery of applications to selected infrastructure environments. Most teams work with multiple environments other than the production, such as development and testing environments, and CD ensures there is an automated way to push code changes to them. CD automation in a modern application performs any necessary deployment tasks while adhering to principles such as \u0026ldquo;infrastructure as code\u0026rdquo; and immutability.\nContinuous integration and delivery requires continuous testing because the objective is to deliver quality applications and code to users. Continuous testing is often implemented as a set of automated regression, performance, security, and other tests that are executed in the CI/CD pipeline.\nA mature CI/CD practice has the option of implementing continuous deployment where application changes run through the CI/CD pipeline and passing builds are deployed directly to production environments.\nCI/CD pipeline being deployed in this workshop  Development and local testing: The developer will work on coding tasks with the Cloud9 IDE environment. Once completed with the task the developer will commit her/his changes to the local git repository and test the changes. Push to remote master branch: When the developer is satisfied with the software changes, the developer will push those changes to the remote master branch. In this workshop this is the AWS CodeCommit Repo. AWS CodePipeline - Commit Event: CodePipeline will monitor AWS CodeCommit for any new commits. When a new commit (code change) is detected a CodeBuild job will be triggered. AWS CodePipeline - Build: Within CodeBuild a series of security tests will be instrumented to validate that code changes are not adding security risks to the application. If security issues are detect, this phase of the CodePipeline process is ended and the pipeline process reports a failure status. If no security issues are detected the build process continues by building and packaging the application. AWS CodePipeline - Postbuilld: Runs additional tests and if those test pass the container is pushed to Amazon ECR.\n AWS CodePipeline - Deploy: If the build process is successful, Codepipeline will update Elastic Container Service that there is a new image. The new image will be deployed and monitored. If all healthchecks pass the new deployment will become the primary service and the previous deployment will be gracefully shutdown. Monitor: ECS and the Application Load Balancer will continually monitor the health of the container and the application and will make the required adjustments to keep the minimum number of healthly container tasks running at all times.\n  Deploy CI/CD Pipeline To deploy the pipeline, run the following commands in Cloud9\u0026rsquo;s terminal\naws cloudformation create-stack --stack-name UnicornPipeline --template-body file://unicorn-store-pipeline.yaml --capabilities CAPABILITY_NAMED_IAM until [[ `aws cloudformation describe-stacks --stack-name \u0026#34;UnicornPipeline\u0026#34; --query \u0026#34;Stacks[0].[StackStatus]\u0026#34; --output text` == \u0026#34;CREATE_COMPLETE\u0026#34; ]]; do echo \u0026#34;The stack is NOT in a state of CREATE_COMPLETE at `date`\u0026#34;; sleep 30; done \u0026amp;\u0026amp; echo \u0026#34;The Stack is built at `date` - Please proceed\u0026#34; This step takes approximately 1 minute and if successfully, you should see the message as below.   The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:46:27 UTC 2019 The stack is NOT in a state of CREATE_COMPLETE at Sun Aug 4 05:46:58 UTC 2019 The Stack is built at Sun Aug 4 05:47:29 UTC 2019 - Please proceed  At this point you should have a fully functioning CI/CD CodePipeline. If you head over to CodePipeline in the AWS console and click on the pipeline that begins with the name UnicorePipeline-Pipeline you will see a similar screen to the one below. The image below is currently in the Deploy stage of the pipeline.\n"
},
{
	"uri": "http://localhost/40_security_testing/30_local_testing.html",
	"title": "Local Testing",
	"tags": [],
	"description": "",
	"content": " Each of the different tests that we have instrumented in our pipeline so far can also be run on the developers local machine. It is not uncommon in pratice to run tests on both the local development machine and within the pipeline. The pipeline test is meant as a mechanism to fail a build stage that has not passed testing, while the local development environment test is meant to provide immediate feedback and diagnostic details to the developer.\nTruffleHog Let\u0026rsquo;s go ahead and run the secret scans on our Cloud9 local development environment.\nFirst we need to install TruffleHog\ncd ~/environment/modernization-devsecops-workshop/ sudo pip install TruffleHog Create a new file in the ~/environment/modernization-devsecops-workshop called secrets.txt, paste in the string below and save the file.\ndbpassword=tSQ9jz7BqjXxNkYFvA0QNuMKtp8 Commit the change to git\ngit add . git commit -m \u0026#34;Testing trufflehog\u0026#34; Now run trufflehog to test the last commit for any secrets\ntrufflehog --regex --max_depth 1 . You should get something similar to the output below The green text states the reason, commit hash, and other interesting information. The yellow text is the actual line that trufflehog found in the commit.\nFor this workshop we are going to leave the file and commit, but on a real world development project we would run either *git revert* or *git reset* to remove the commit from our history.  Hadolint This tool is very easy to run in our Cloud9 environment as it runs using Docker, which is already installed.\nTo run hadolint copy and paste the following into the Cloud9 terminal\ncd ~/environment/modernization-devsecops-workshop/ docker run --rm -i hadolint/hadolint \u0026lt; Dockerfile Nothing should have been found. So let\u0026rsquo;s simulate an issue that hadolint will detect. Open up the Dockerfile and add the following text to the bottom of the file and save.\nRUN cd /tmp \u0026amp;\u0026amp; echo \u0026#34;hello!\u0026#34; Now run hadolint again\ndocker run --rm -i hadolint/hadolint \u0026lt; Dockerfile This time you should see the following output  /dev/stdin:22 DL3003 Use WORKDIR to switch to a directory \nIf you look through the hadolint website https://github.com/hadolint/hadolint you will see that DL3003 is because of our usage of cd instead of the preferred WORKDIR.\nTesting We ran each of the commands manually, but normally you would want to add this as part of a unit testing suite.\nAs an example, run the following command\ncd ~/environment/modernization-devsecops-workshop/ ./test_runner.sh The output should look like the following Notice that both TruffleHog and Hadolint scanned for potential security issues and reported results. An alternative to running security scans as part of a unit test script, scans can also be ran as part of git hooks. Hooks are a way for git to run scripts before or after git events such as commit or push. TruffleHog could run right after a commit and hadolint could run pre commit. This suggestion is made in an effort to reduce friction with developers. Successful implementations of security in DevSecOps integrates with a developers normal workflow and does not require additional steps or processes that can easily be forgotten. And having security scans on developers local environments has the benefit of shortening the feedback loop.\n"
},
{
	"uri": "http://localhost/30_unicorn_store_ci_cd.html",
	"title": "Unicorn Store CI/CD",
	"tags": [],
	"description": "",
	"content": " Unicorn Store CI/CD  Setup Basic Services   Push to Repo   Deploy ECS Fargate Service   Deploy CI/CD Pipeline   "
},
{
	"uri": "http://localhost/40_security_testing.html",
	"title": "Security Testing",
	"tags": [],
	"description": "",
	"content": " Security Testing  Testing Introduction   Test Pipeline   Secrets Scanning   Docker Scanning   Local Testing   "
},
{
	"uri": "http://localhost/50_conclusion.html",
	"title": "Conclusion",
	"tags": [],
	"description": "",
	"content": " Conclusion  Congratulations   Cleanup   "
},
{
	"uri": "http://localhost/categories.html",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "http://localhost/tags.html",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
}]